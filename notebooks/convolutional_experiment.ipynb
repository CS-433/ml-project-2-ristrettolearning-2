{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import seaborn as sns\n",
    "import ristretto.activations as ra\n",
    "import ristretto.models as rm\n",
    "import ristretto.utils as ru\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "# from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set pytorch precision\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "torch.set_default_dtype(torch.float32)\n",
    "# activate \n",
    "ra.ReLUFunction.print_when_zero = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epoch_val(metrics, epochs=10, batch_size=128):\n",
    "    \"\"\"Gets the accuracy of an epoch for a given model.\"\"\"\n",
    "    epoch_val = np.arange(epochs)\n",
    "    model_epoch =[]\n",
    "\n",
    "    for m in range(len(metrics)):\n",
    "        for i in range(epochs):\n",
    "            len_epoch = int(len(metrics[m][\"validation\"]['correct'])/epochs)\n",
    "            index = i*len_epoch\n",
    "            epoch_val[i] = (metrics[m][\"validation\"]['correct'][index:index+len_epoch].sum())\n",
    "            aux = epoch_val.copy()/10000\n",
    "        model_epoch.append(aux)\n",
    "    return model_epoch\n",
    "\n",
    "\n",
    "def get_epoch_train(metrics, epochs=10, batch_size=128):\n",
    "    \"\"\"Gets the accuracy of an epoch for a given model.\"\"\"\n",
    "    epoch_val = np.arange(epochs)\n",
    "    model_epoch =[]\n",
    "\n",
    "    for m in range(len(metrics)):\n",
    "        for i in range(epochs):\n",
    "            len_epoch = int(len(metrics[m][\"train\"]['loss'])/epochs)\n",
    "            index = i*len_epoch\n",
    "            epoch_val[i] = (metrics[m][\"train\"]['loss'][index:index+len_epoch].sum())\n",
    "            aux = epoch_val.copy()/600000\n",
    "        model_epoch.append(aux)\n",
    "    return model_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = [0, 1, 2, 4, 8]\n",
    "\n",
    "new_models = []\n",
    "for activition in activations:\n",
    "    new_models.append(rm.ResNet(activation=partial(ra.ReLU, activition), seed=42069))\n",
    "      \n",
    "model_32 = [rm.ResNet(activation=partial(ra.ReLU, 0), seed=42069)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is just to know the index of the models for the plots. \n",
    "aux = 0\n",
    "rel = 0 \n",
    "\n",
    "for activation in activations:\n",
    "    print(f\"index {aux +1} --> model {aux+2}\")\n",
    "    print(f\"Activation: {activation} alpha: {rel}\")\n",
    "    print(f\"Model: {new_models[aux]}\")\n",
    "    aux += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_32 = model_32 + new_models\n",
    "\n",
    "# activate \n",
    "ra.ReLUFunction.print_when_zero = True\n",
    "\n",
    "epochs = 20\n",
    "metrics_32 = ru.train_multiple_models(\n",
    "    models_32,\n",
    "    ru.default.DATA_LOADERS['MNIST'],\n",
    "    epochs=epochs,\n",
    "    metrics_fn=lambda m, p, y: {\"weight_sum\": ru.get_weight_sum(m)}\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Took 20min to run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"convolutional_output1_32.bin\", \"wb\") as output:\n",
    "    pickle.dump(metrics_32, output)\n",
    "    output.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"numbers models: \",len(metrics_32),\"Which contain: \")\n",
    "print(metrics_32[0].keys())\n",
    "print('train contains: ')\n",
    "print(metrics_32[0]['train'].keys()) \n",
    "print('validation contains: ')\n",
    "print(metrics_32[0]['validation'].keys()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = pd.DataFrame({\n",
    "    \"0 vs 0\": np.abs(metrics_32[0][\"train\"]['weight_sum'] - metrics_32[1][\"train\"]['weight_sum']),\n",
    "    \"0 vs 1\": np.abs(metrics_32[0][\"train\"]['weight_sum'] - metrics_32[2][\"train\"]['weight_sum']),\n",
    "    \"0 vs 2\": np.abs(metrics_32[0][\"train\"]['weight_sum'] - metrics_32[3][\"train\"]['weight_sum']),\n",
    "    \"0 vs 4\": np.abs(metrics_32[0][\"train\"]['weight_sum'] - metrics_32[4][\"train\"]['weight_sum']),\n",
    "    \"0 vs 8\": np.abs(metrics_32[0][\"train\"]['weight_sum'] - metrics_32[5][\"train\"]['weight_sum'])\n",
    "})\n",
    "sns.lineplot(data=diff, dashes=False)\n",
    "plt.xlabel(\"Epoch/batch\")\n",
    "plt.ylabel(\"Absolute difference in weight sum\")\n",
    "plt.title(\"Difference in weight sum between models with different ReLU thresholds (32-bit precision)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_32 = get_epoch_train(metrics_32, epochs=epochs, batch_size=128)\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.plot(loss_32[1], label='ReLU 0')\n",
    "plt.plot(loss_32[2], label='ReLU 1')\n",
    "plt.plot(loss_32[3], label='ReLU 2')\n",
    "plt.plot(loss_32[4], label='ReLU 4')\n",
    "plt.plot(loss_32[5], label='ReLU 8')\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.suptitle(\"Error in each epoch with different ReLu'(0) values\\n 32 bit precision \", fontsize=20, y=1.05)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model32_epoch = get_epoch_val(metrics_32, epochs=epochs, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.plot((1-model32_epoch[1])*100, label='ReLU 0')\n",
    "plt.plot((1-model32_epoch[2])*100, label='ReLU 1')\n",
    "plt.plot((1-model32_epoch[3])*100, label='ReLU 2')\n",
    "plt.plot((1-model32_epoch[4])*100, label='ReLU 4')\n",
    "plt.plot((1-model32_epoch[5])*100, label='ReLU 8')\n",
    "plt.ylabel('%Error', fontsize=14)\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.suptitle(\"Error in each epoch with different ReLu'(0) values\\n 32 bit precision \", fontsize=20, y=1.05)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When trained with 16-bit precision the difference between the models is even greater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set pytorch precision\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "torch.set_default_dtype(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = [0, 1, 2, 4, 8]\n",
    "\n",
    "new_models_16 = []\n",
    "for activition in activations:\n",
    "    new_models_16.append(rm.ResNet(activation=partial(ra.ReLU, activition), seed=42069))\n",
    "      \n",
    "model_16 = [rm.ResNet(activation=partial(ra.ReLU, 0), seed=42069)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is just to know the index of the models for the plots. \n",
    "aux = 0\n",
    "rel = 0 \n",
    "\n",
    "for activation in activations:\n",
    "    print(f\"index {aux +1} --> model {aux+2}\")\n",
    "    print(f\"Activation: {activation} alpha: {rel}\")\n",
    "    print(f\"Model: {new_models_16[aux]}\")\n",
    "    aux += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "models_16 = model_16 + new_models_16\n",
    "\n",
    "metrics_16 = ru.train_multiple_models(\n",
    "    models_16,\n",
    "    ru.default.DATA_LOADERS['MNIST'],\n",
    "    epochs=epochs,\n",
    "    metrics_fn=lambda m, p, y: {\"weight_sum\": ru.get_weight_sum(m)}\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ran in 12 30.4 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = pd.DataFrame({\n",
    "    \"0 vs 0\": np.abs(metrics_16[0][\"train\"]['weight_sum'] - metrics_16[1][\"train\"]['weight_sum']),\n",
    "    \"0 vs 1\": np.abs(metrics_16[0][\"train\"]['weight_sum'] - metrics_16[2][\"train\"]['weight_sum']),\n",
    "    \"0 vs 2\": np.abs(metrics_16[0][\"train\"]['weight_sum'] - metrics_16[3][\"train\"]['weight_sum']),\n",
    "    \"0 vs 4\": np.abs(metrics_16[0][\"train\"]['weight_sum'] - metrics_16[4][\"train\"]['weight_sum']),\n",
    "    \"0 vs 8\": np.abs(metrics_16[0][\"train\"]['weight_sum'] - metrics_16[5][\"train\"]['weight_sum'])\n",
    "})\n",
    "\n",
    "sns.lineplot(data=diff, dashes=False)\n",
    "plt.xlabel(\"Epoch/batch\")\n",
    "plt.ylabel(\"Absolute difference in weight sum\")\n",
    "plt.title(\"Difference in weight sum between models with different ReLU thresholds (16-bit precision)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_16 = get_epoch_train(metrics_16, epochs=20, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.plot(loss_16[1], label='ReLU 0')\n",
    "plt.plot(loss_16[2], label='ReLU 1')\n",
    "plt.plot(loss_16[3], label='ReLU 2')\n",
    "plt.plot(loss_16[4], label='ReLU 4')\n",
    "plt.plot(loss_16[5], label='ReLU 8')\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.suptitle(\"Error in each epoch with different ReLu'(0) values\\n 16 bit precision \", fontsize=20, y=1.05)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model16_epoch = get_epoch_val(metrics_16, epochs=20, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.plot((1-model16_epoch[1])*100, label='ReLU 0')\n",
    "plt.plot((1-model16_epoch[2])*100, label='ReLU 1')\n",
    "plt.plot((1-model16_epoch[3])*100, label='ReLU 2')\n",
    "plt.plot((1-model16_epoch[4])*100, label='ReLU 4')\n",
    "plt.plot((1-model16_epoch[5])*100, label='ReLU 8')\n",
    "plt.ylabel('%Error', fontsize=14)\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.suptitle(\"Error in each epoch with different ReLu'(0) values\\n 16 bit precision \", fontsize=20, y=1.05)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"convolutional_output1_16.bin\", \"wb\") as output: #Im storing the esperiment results for further testing \n",
    "    pickle.dump(metrics_16, output)\n",
    "    output.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open(\"convolutional_output1_16.bin\", \"rb\") as data:\n",
    "    metrics_16 = pickle.load(data)\n",
    "    \n",
    "with open(\"convolutional_output1_32.bin\", \"rb\") as data:\n",
    "    metrics_32 = pickle.load(data)\n",
    "\n",
    "df_16 = pd.DataFrame(metrics_16)\n",
    "df_32 = pd.DataFrame(metrics_32)\n",
    "batch = 128\n",
    "alphas = [0,0,1,2,4,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_16 = pd.DataFrame(columns=['relu', 'test_accuracy'])\n",
    "\n",
    "for i in range(len(alphas)):\n",
    "    for j in range(len(metrics_16[i][\"validation\"][\"loss\"].values)):\n",
    "        new_df_16 = new_df_16.append({'relu': alphas[i], 'test_accuracy': metrics_16[i]['validation']['correct'].values[j] /batch}, ignore_index=True);\n",
    "\n",
    "new_df_32 = pd.DataFrame(columns=['relu', 'test_accuracy'])\n",
    "for i in range(len(alphas)):\n",
    "    for j in range(len(metrics_32[i][\"validation\"][\"loss\"].values)):\n",
    "        new_df_32 = new_df_32.append({'relu': alphas[i], 'test_accuracy': metrics_32[i]['validation']['correct'].values[j] /batch}, ignore_index=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(data=new_df_16, x=\"relu\", y=\"test_accuracy\", kind=\"box\", hue=\"relu\", height=4, aspect=2 )\n",
    "plt.get_figlabels()\n",
    "plt.legend(title = \"ReLU'(0)\", loc='best', bbox_to_anchor=(0.75, 0.3, 0.5, 0.5));\n",
    "plt.suptitle(\"Test accuracy for different\\n ReLU thresholds (16-bit precision)\", fontsize=18, y=1.2, x=0.6);\n",
    "plt.xlabel(\"ReLU'(0)\", fontsize=18); \n",
    "plt.ylabel('Test accuracy', fontsize=18);\n",
    "locs, labels = plt.xticks()  # Get the current locations and labels.\n",
    "plt.xticks([-.32,0.84,2,3.16,4.32], labels, fontsize=18);\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h= sns.catplot(data=new_df_32, x=\"relu\", y=\"test_accuracy\", kind=\"box\", hue=\"relu\", height=4, aspect=2)\n",
    "plt.legend(title = \"ReLU'(0)\", loc='best', bbox_to_anchor=(0.75, 0.3, 0.5, 0.5));\n",
    "plt.suptitle(\"Test accuracy for different\\n ReLU thresholds (32-bit precision)\", fontsize=18, y=1.2, x=0.6);\n",
    "plt.xlabel(\"ReLU'(0)\", fontsize=18);\n",
    "plt.xticks([-.32,0.84,2,3.16,4.32], labels, fontsize=18);\n",
    "plt.ylabel('Test accuracy', fontsize=18);\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4))\n",
    "sns.boxplot(data=new_df_16, x=\"relu\", y=\"test_accuracy\" , hue=\"relu\", color=\"blue\") \n",
    "sns.boxplot(data=new_df_32, x=\"relu\", y=\"test_accuracy\", hue=\"relu\" , color=\"red\")\n",
    "plt.legend(title = \"ReLU'(0)\", loc='best', bbox_to_anchor=(0.75, 0.3, 0.5, 0.5));\n",
    "plt.suptitle(\"Test accuracy for different\\n ReLU thresholds (32 and 16-bit precision comparisson)\", fontsize=18, y=1.1, x=0.6);\n",
    "plt.text(4.7, 1, '16-bit precision', fontsize=18, color='blue')\n",
    "plt.text(4.7, 0.9, '32-bit precision', fontsize=18, color='red')\n",
    "plt.xlabel(\"ReLU'(0)\", fontsize=18);\n",
    "plt.xticks([-.32,0.84,2,3.16,4.32], labels, fontsize=18);\n",
    "plt.ylabel('Test accuracy', fontsize=18);\n",
    "plt.grid(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d74a85df572dd13003d86cd6ee7686fe60fc998cf9a3b0e8f076cf20edde930"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
